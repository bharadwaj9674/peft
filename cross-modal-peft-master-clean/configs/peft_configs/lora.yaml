# LoRA (Low-Rank Adaptation) configuration

# Data configuration (same as default)
data:
  root: "../data"
  batch_size: 32
  num_workers: 4
  max_text_length: 77
  audio_length: 10
  audio_sample_rate: 16000
  image_size: 224

# Model configuration (same as default)
model:
  embedding_dim: 512
  dropout: 0.1

  # Text encoder configuration
  text:
    model_name: "roberta-base"
    freeze_base: true
    output_dim: 768

  # Audio encoder configuration
  audio:
    model_name: "MIT/ast-finetuned-audioset-10-10-0.4593"
    freeze_base: true
    output_dim: 768

  # Image encoder configuration
  image:
    model_name: "google/vit-base-patch16-224"
    freeze_base: true
    output_dim: 768

# LoRA-specific PEFT configuration
peft:
  enabled: true
  method: "lora"

  # Text LoRA configuration
  text:
    rank: 8              # Low rank for the decomposition
    alpha: 16            # Scaling factor (usually 2x the rank)
    dropout: 0.1         # Dropout probability
    target_modules: ["query", "key", "value", "dense"]  # Which modules to apply LoRA to

  # Audio LoRA configuration
  audio:
    rank: 8
    alpha: 16
    dropout: 0.1
    target_modules: ["query", "key", "value", "dense"]

  # Image LoRA configuration
  image:
    rank: 8
    alpha: 16
    dropout: 0.1
    target_modules: ["query", "key", "value", "dense"]

# Training configuration
training:
  num_epochs: 1
  learning_rate: 5e-5
  weight_decay: 0.01
  device: "cuda"
  output_dir: "./outputs/lora"
  log_interval: 10
  save_interval: 1
  eval_interval: 1